{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:19:45.762208Z",
     "iopub.status.busy": "2024-12-02T23:19:45.750073Z",
     "iopub.status.idle": "2024-12-02T23:19:48.189757Z",
     "shell.execute_reply": "2024-12-02T23:19:48.189757Z",
     "shell.execute_reply.started": "2024-12-02T23:19:45.762208Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from time import time, sleep\n",
    "\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:19:48.224945Z",
     "iopub.status.busy": "2024-12-02T23:19:48.214201Z",
     "iopub.status.idle": "2024-12-02T23:19:48.766420Z",
     "shell.execute_reply": "2024-12-02T23:19:48.763419Z",
     "shell.execute_reply.started": "2024-12-02T23:19:48.224945Z"
    }
   },
   "outputs": [],
   "source": [
    "#connection with robot\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:19:49.443713Z",
     "iopub.status.busy": "2024-12-02T23:19:49.442716Z",
     "iopub.status.idle": "2024-12-02T23:19:49.608573Z",
     "shell.execute_reply": "2024-12-02T23:19:49.606803Z",
     "shell.execute_reply.started": "2024-12-02T23:19:49.443713Z"
    }
   },
   "outputs": [],
   "source": [
    "#===============ROBOT INSTRUCTIONS==================================\n",
    "#function to get the value of the prox\n",
    "async def get_prox_value():\n",
    "    await node.wait_for_variables({\"prox.horizontal\"})\n",
    "    return list(node[\"prox.horizontal\"])\n",
    "\n",
    "#set the speed of the motors\n",
    "async def set_motor_speed(left, right):\n",
    "    await node.set_variables({\"motor.left.target\": [left], \"motor.right.target\": [right]})\n",
    "\n",
    "async def get_motor_speed():\n",
    "    await node.wait_for_variables({\"motor.left.speed\", \"motor.right.speed\"})\n",
    "    return node[\"motor.left.speed\"], node[\"motor.right.speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:19:50.619998Z",
     "iopub.status.busy": "2024-12-02T23:19:50.619004Z",
     "iopub.status.idle": "2024-12-02T23:19:50.891640Z",
     "shell.execute_reply": "2024-12-02T23:19:50.891640Z",
     "shell.execute_reply.started": "2024-12-02T23:19:50.619998Z"
    }
   },
   "outputs": [],
   "source": [
    "await set_motor_speed(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part initializes the detector. It calibrates the camera, and computes the perspective transformation from the first image.\n",
    "\n",
    "Make sure to setup the camera properly and still. The first image is the most important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:19:54.133668Z",
     "iopub.status.busy": "2024-12-02T23:19:54.131674Z",
     "iopub.status.idle": "2024-12-02T23:19:54.810269Z",
     "shell.execute_reply": "2024-12-02T23:19:54.810269Z",
     "shell.execute_reply.started": "2024-12-02T23:19:54.133668Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-opencv-capture-video-from-camera/\n",
    "# Initialize the camera\n",
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "# Get the default frame width and height\n",
    "frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:19:58.231668Z",
     "iopub.status.busy": "2024-12-02T23:19:58.230673Z",
     "iopub.status.idle": "2024-12-02T23:19:59.060669Z",
     "shell.execute_reply": "2024-12-02T23:19:59.060669Z",
     "shell.execute_reply.started": "2024-12-02T23:19:58.231668Z"
    }
   },
   "outputs": [],
   "source": [
    "# take a picture\n",
    "ret, initial_image = cam.read()\n",
    "plt.imshow(cv2.cvtColor(initial_image, cv2.COLOR_BGR2RGB))\n",
    "#save the image\n",
    "# cv2.imwrite('calibration_image_test.jpg', initial_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image\n",
    "cv2.imwrite('calibration_image.jpg', initial_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:20:00.155324Z",
     "iopub.status.busy": "2024-12-02T23:20:00.154360Z",
     "iopub.status.idle": "2024-12-02T23:20:00.380106Z",
     "shell.execute_reply": "2024-12-02T23:20:00.380106Z",
     "shell.execute_reply.started": "2024-12-02T23:20:00.155324Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.vision import VisionDetector\n",
    "from src.utils import add_robot\n",
    "# initial_image= cv2.imread('calibration_image_test.jpg')\n",
    "aruco_info = json.load(open('../assets/aruco/state.json', 'r'))\n",
    "\n",
    "map_size = (1179, 830) # (width, height) in mm\n",
    "detector = VisionDetector(initial_image, map_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the initial corrected image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:20:02.521431Z",
     "iopub.status.busy": "2024-12-02T23:20:02.519424Z",
     "iopub.status.idle": "2024-12-02T23:20:03.368520Z",
     "shell.execute_reply": "2024-12-02T23:20:03.368520Z",
     "shell.execute_reply.started": "2024-12-02T23:20:02.521431Z"
    }
   },
   "outputs": [],
   "source": [
    "# take a picture\n",
    "ret, initial_image = cam.read()\n",
    "corrected_image = detector.get_corrected_image(initial_image)\n",
    "plt.imshow(cv2.cvtColor(corrected_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can process this image with our computer vision pipeline, to compute the shortest path to follow for the robot to collect all the red circle objectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.path_planning import path_planning, create_obstacle_map\n",
    "from src.vision import extend_polygons\n",
    "from src.utils import add_route, add_circles, add_polygons\n",
    "\n",
    "robot_size = 100\n",
    "\n",
    "ret, initial_image = cam.read()\n",
    "corrected_image = detector.get_corrected_image(initial_image)\n",
    "\n",
    "robot_position_cv, robot_orientation_cv, robot_corners = detector.get_robot_pose(corrected_image, is_corrected=True)\n",
    "\n",
    "# add a white circle around the robot\n",
    "hidden_robot_image = cv2.circle(corrected_image.copy(), tuple(robot_position_cv.astype(int)), robot_size, (255, 255, 255), -1)\n",
    "\n",
    "polygons = detector.find_polygons(hidden_robot_image, min_area=200, thresh_1=127, thresh_2=255)\n",
    "extended_polygons = extend_polygons(polygons, robot_size)\n",
    "polygon_image = add_polygons(corrected_image, extended_polygons)\n",
    "\n",
    "circles = detector.find_circles(polygon_image, 1, 300, 300, 40) #215, 24\n",
    "circle_positions = circles.squeeze().reshape(-1, 3)[:, :2]\n",
    "circle_image = add_circles(polygon_image, circles)\n",
    "\n",
    "image_aruco = add_robot(circle_image, robot_position_cv, robot_orientation_cv, robot_corners)\n",
    "image_circles = add_circles(image_aruco, circles)\n",
    "optimal_route, optimal_route_positions, points, adjacency_matrix = path_planning(robot_position_cv, circle_positions, extended_polygons, corrected_image.shape)\n",
    "route_image = add_route(image_circles, np.int32(optimal_route_positions))\n",
    "all_target_cv = np.array(optimal_route_positions)[1:, :]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(route_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the obstacle map and the path that was found to convince ourselves that it is indeed the shortest possible path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the obstacle map\n",
    "obstacle_map = create_obstacle_map(extended_polygons, corrected_image.shape)\n",
    "circled = add_circles(obstacle_map, circles)\n",
    "route_image = add_route(circled, np.int32(optimal_route_positions))\n",
    "plt.imshow(circled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing useful variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything, let's light up the thymio :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T23:16:16.723622Z",
     "iopub.status.busy": "2024-12-02T23:16:16.721660Z",
     "iopub.status.idle": "2024-12-02T23:16:17.496718Z",
     "shell.execute_reply": "2024-12-02T23:16:17.496718Z",
     "shell.execute_reply.started": "2024-12-02T23:16:16.723622Z"
    }
   },
   "outputs": [],
   "source": [
    "leds_top = [25,0,25]\n",
    "aw(node.set_variables({\"leds.top\" : leds_top}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can convert the different variables we need in the mathematical basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.geometry import convert_points, convert_vec, get_angle, convert_angle_to_vector\n",
    "from src.utils import add_line, add_route, add_circles, add_polygons, add_robot, add_point\n",
    "\n",
    "robot_pos_m = convert_points(robot_position_cv, y_max=map_size[1])\n",
    "robot_orientation_m = convert_vec(robot_orientation_cv)\n",
    "all_target_m = convert_points(all_target_cv, y_max=map_size[1])\n",
    "if circle_positions.squeeze().ndim == 1:\n",
    "    circle_positions = circle_positions.reshape(-1)\n",
    "else:\n",
    "    circle_positions = circle_positions.squeeze()[:, :2]\n",
    "objectives_m = convert_points(circle_positions, y_max=map_size[1])\n",
    "robot_angle_m = get_angle(np.array([1, 0]), robot_orientation_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controller initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.navigation import FSMController\n",
    "\n",
    "fsm = FSMController(\n",
    "    robot_pos_m = robot_pos_m,\n",
    "    all_target_m = all_target_m,\n",
    "    objectives_m = objectives_m,\n",
    "    extended_polygons = extended_polygons,\n",
    "    img_shape = corrected_image.shape,\n",
    "    first_prox = [0, 25, 0],\n",
    "    prox_obstacle_threshold = 100,\n",
    "    intensity = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kalman_filter import KalmanFilter\n",
    "\n",
    "dt_loop = 100 / 1000         # in s\n",
    "DIST_WHEEL =  95        # in mm\n",
    "\n",
    "speed_convertor = lambda x: 0.33*x - 0.89\n",
    "\n",
    "kf = KalmanFilter(\n",
    "    robot_pos_m=robot_pos_m,\n",
    "    robot_angle_m=robot_angle_m,\n",
    "    speed_convertor = speed_convertor,\n",
    "    DIST_WHEEL = DIST_WHEEL,\n",
    "    CAM_POS_MEASUREMENT_VAR = 0.1,\n",
    "    CAM_ANGLE_MEASUREMENT_VAR=0.1,\n",
    "    PROCESS_POS_VAR=1.5,\n",
    "    PROCESS_ANGLE_VAR=0.003,\n",
    ")\n",
    "\n",
    "speed_left, speed_right = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import draw_kalman_pos, draw_kalman_angle\n",
    "from time import time\n",
    "\n",
    "kidnapping_threshold = 100\n",
    "robot_in_vue = True\n",
    "y_max = map_size[1]\n",
    "start = time()\n",
    "aw(node.set_variables({\"leds.top\" : leds_top}))\n",
    "vec_to_print = np.array([0.,0.])\n",
    "\n",
    "cv2.namedWindow(\"real_image\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"real_image\", *map_size)\n",
    "\n",
    "cv2.namedWindow(\"kalman_pos\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"kalman_pos\", *map_size)\n",
    "\n",
    "cv2.namedWindow(\"kalman_angle\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"kalman_angle\", *map_size)\n",
    "\n",
    "cv2.namedWindow(\"kalman_angle\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"kalman_angle\", (640, 480))\n",
    "\n",
    "video_writer = cv2.VideoWriter('video.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, map_size) \n",
    "kalman_video_writer = cv2.VideoWriter('kalman_position.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, map_size)\n",
    "kalman_angle_writer = cv2.VideoWriter('kalman_angle.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, (640, 480))\n",
    "\n",
    "while True:\n",
    "    #get the prox sensors values\n",
    "    prox = await get_prox_value()\n",
    "\n",
    "    # If we can't get the robot pose for any reason, we only use kalman estimation. If we get vision back and the robot is far enough from previous viewed position, we have a kidnapping\n",
    "    try:\n",
    "        ret, frame = cam.read()\n",
    "        corrected_image = detector.get_corrected_image(frame)\n",
    "        robot_pos_cv, robot_orientation_cv, robot_corners_cv = detector.get_robot_pose(corrected_image, is_corrected=True)\n",
    "        robot_pos_m = convert_points(robot_pos_cv, y_max)\n",
    "        robot_orientation_m = convert_vec(robot_orientation_cv)\n",
    "        robot_angle_m = get_angle(np.array([1, 0]), robot_orientation_m)\n",
    "        img_aruco = add_robot(corrected_image, robot_pos_cv, np.array(robot_orientation_cv), np.array(robot_corners_cv))\n",
    "        if not robot_in_vue:\n",
    "            print('robot back in vue')\n",
    "            if np.linalg.norm(robot_pos_m - old_robot_pos_m) > kidnapping_threshold:\n",
    "                print('kidnapping\\nReplanning the route given the attained objectives')\n",
    "                fsm.recompute_global_path(robot_pos_m)\n",
    "        robot_in_vue = True\n",
    "    except:\n",
    "        img_aruco = corrected_image\n",
    "        robot_pos_m = None\n",
    "        robot_orientation_m = None\n",
    "        robot_in_vue = False\n",
    "\n",
    "    # kalman filter step\n",
    "    speed_measure_left, speed_measure_right = await get_motor_speed()\n",
    "    \n",
    "    z_measure = np.append(robot_pos_m, robot_angle_m)\n",
    "    if robot_pos_m is None or robot_orientation_m is None:\n",
    "        z_measure = None\n",
    "\n",
    "    end = time()\n",
    "    dt = end - start\n",
    "\n",
    "    motor_speeds = np.array([speed_measure_left, speed_measure_right])\n",
    "    robot_pos_kalman, robot_angle_kalman, covariance_kalman = kf.estimate(motor_speeds, z_measure, dt)\n",
    "    robot_orientation_kalman = convert_angle_to_vector(robot_angle_kalman)\n",
    "    \n",
    "    # do everything :=) for getting the command\n",
    "    leds_top, speed_left, speed_right, stop = fsm.get_command(prox, robot_pos_kalman, robot_orientation_kalman)\n",
    "    \n",
    "    \n",
    "    # setting the speed of the motors\n",
    "    start = time()\n",
    "    await set_motor_speed(speed_left, speed_right)\n",
    "    aw(node.set_variables({\"leds.top\" : leds_top}))\n",
    "\n",
    "    if stop: break #all target are reached so end the program\n",
    "\n",
    "    if robot_in_vue:\n",
    "        old_robot_pos_m = robot_pos_m\n",
    "\n",
    "    # ----------- DRAWINGS ----------- #\n",
    "    #display the image\n",
    "    route_cv = convert_points(fsm.current_path, y_max)\n",
    "    img_final = add_route(img_aruco, route_cv.astype(int))\n",
    "    cv2.imshow('real_image', img_final)\n",
    "    video_writer.write(img_final)\n",
    "\n",
    "    # Kalman estimated position density\n",
    "    img_kalman_pos      = draw_kalman_pos(robot_pos_kalman, covariance_kalman[:2, :2], map_size)\n",
    "    cv2.imshow('kalman_pos', img_kalman_pos.T[::-1, :]) \n",
    "    kalman_video_writer.write(cv2.cvtColor(img_kalman_pos.T[::-1, :], cv2.COLOR_GRAY2BGR))\n",
    "    \n",
    "    # kalman estimated angle density\n",
    "    img_kalman_angle = draw_kalman_angle(robot_angle_kalman, covariance_kalman[2, 2])\n",
    "    cv2.imshow('kalman_angle', img_kalman_angle)\n",
    "    kalman_angle_writer.write(cv2.cvtColor(img_kalman_angle, cv2.COLOR_RGBA2BGR))\n",
    "    # print(img_kalman_angle.shape)\n",
    "    # break\n",
    "\n",
    "\n",
    "    # ----------- KEYBOARD INPUT ----------- #\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    # if 'space' -> pause the loop\n",
    "    if key == ord(' '):\n",
    "        print(\"programme en pause\")\n",
    "        await set_motor_speed(0, 0)\n",
    "        while(1):\n",
    "            if cv2.waitKey(1) == ord(' '):\n",
    "                break\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                stop = 1\n",
    "                break\n",
    "                \n",
    "    # if 'q' -> exit the loop\n",
    "    if key == ord('q') or stop:\n",
    "        print(\"terminated by user\")\n",
    "        break\n",
    "\n",
    "await set_motor_speed(0, 0)\n",
    "\n",
    "# recording 20 frames at the end of the loop\n",
    "for i in range(20):\n",
    "    ret, frame = cam.read()\n",
    "    corrected_image = detector.get_corrected_image(frame)\n",
    "    try:\n",
    "        robot_pos_cv, robot_orientation_cv, robot_corners_cv = detector.get_robot_pose(corrected_image, is_corrected=True)\n",
    "        robot_pos_m = convert_points(robot_pos_cv, y_max)\n",
    "        robot_orientation_m = convert_vec(robot_orientation_cv)\n",
    "        robot_angle_m = get_angle(np.array([1, 0]), robot_orientation_m)\n",
    "        img_aruco = add_robot(corrected_image, robot_pos_cv, np.array(robot_orientation_cv), np.array(robot_corners_cv))\n",
    "        cv2.imshow('real_image', img_aruco)\n",
    "        video_writer.write(img_aruco)\n",
    "    except:\n",
    "        cv2.imshow('real_image', corrected_image)\n",
    "        video_writer.write(corrected_image)\n",
    "\n",
    "    cv2.imshow('kalman_pos', img_kalman_pos.T[::-1, :])\n",
    "    kalman_video_writer.write(cv2.cvtColor(img_kalman_pos.T[::-1, :], cv2.COLOR_GRAY2BGR))\n",
    "    cv2.imshow('kalman_angle', img_kalman_angle)\n",
    "    kalman_angle_writer.write(cv2.cvtColor(img_kalman_angle, cv2.COLOR_RGBA2BGR))\n",
    "\n",
    "    await client.sleep(0.2)\n",
    "# Once finished, set the speed of the motors to 0\n",
    "video_writer.release()\n",
    "kalman_video_writer.release()\n",
    "kalman_angle_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
